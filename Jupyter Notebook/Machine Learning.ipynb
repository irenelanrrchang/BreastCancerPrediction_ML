{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and check the data\n",
    "cancer = pd.read_csv('../Resources/data.csv')\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0         0.2419           ...                    25.38          17.33   \n",
       "1         0.1812           ...                    24.99          23.41   \n",
       "2         0.2069           ...                    23.57          25.53   \n",
       "3         0.2597           ...                    14.91          26.50   \n",
       "4         0.1809           ...                    22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data\n",
    "cancer = cancer.iloc[:,:-1]\n",
    "cancer = cancer.drop(cancer.columns[[0]], axis=1) \n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref: 21-2-6\n",
    "# Data Pre Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "target = cancer[\"diagnosis\"]\n",
    "data = cancer.drop(\"diagnosis\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.930\n",
      "k: 3, Train/Test Score: 0.951/0.930\n",
      "k: 5, Train/Test Score: 0.934/0.965\n",
      "k: 7, Train/Test Score: 0.937/0.958\n",
      "k: 9, Train/Test Score: 0.934/0.958\n",
      "k: 11, Train/Test Score: 0.934/0.979\n",
      "k: 13, Train/Test Score: 0.925/0.972\n",
      "k: 15, Train/Test Score: 0.923/0.965\n",
      "k: 17, Train/Test Score: 0.925/0.965\n",
      "k: 19, Train/Test Score: 0.920/0.965\n",
      "k: 21, Train/Test Score: 0.918/0.965\n",
      "k: 23, Train/Test Score: 0.918/0.965\n",
      "k: 25, Train/Test Score: 0.915/0.951\n",
      "k: 27, Train/Test Score: 0.918/0.951\n",
      "k: 29, Train/Test Score: 0.915/0.951\n",
      "k: 31, Train/Test Score: 0.915/0.951\n",
      "k: 33, Train/Test Score: 0.913/0.944\n",
      "k: 35, Train/Test Score: 0.915/0.944\n",
      "k: 37, Train/Test Score: 0.918/0.944\n",
      "k: 39, Train/Test Score: 0.913/0.951\n",
      "k: 41, Train/Test Score: 0.911/0.951\n",
      "k: 43, Train/Test Score: 0.911/0.944\n",
      "k: 45, Train/Test Score: 0.911/0.951\n",
      "k: 47, Train/Test Score: 0.911/0.951\n",
      "k: 49, Train/Test Score: 0.904/0.944\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRJYsjDHGRGTJwhhjTET/HxT/0MSnyHAQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f0ecf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 50, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 50, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 50, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=7 Test Acc: 0.958\n"
     ]
    }
   ],
   "source": [
    "# Note that k: 11 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=7 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methodology_#Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = cancer.drop(\"diagnosis\", axis=1)\n",
    "y = cancer[\"diagnosis\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Deep Learning Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='relu', input_dim=30))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " - 0s - loss: 0.5585 - acc: 0.7418\n",
      "Epoch 2/60\n",
      " - 0s - loss: 0.2498 - acc: 0.9460\n",
      "Epoch 3/60\n",
      " - 0s - loss: 0.1512 - acc: 0.9601\n",
      "Epoch 4/60\n",
      " - 0s - loss: 0.1120 - acc: 0.9742\n",
      "Epoch 5/60\n",
      " - 0s - loss: 0.0923 - acc: 0.9789\n",
      "Epoch 6/60\n",
      " - 0s - loss: 0.0788 - acc: 0.9836\n",
      "Epoch 7/60\n",
      " - 0s - loss: 0.0695 - acc: 0.9859\n",
      "Epoch 8/60\n",
      " - 0s - loss: 0.0623 - acc: 0.9859\n",
      "Epoch 9/60\n",
      " - 0s - loss: 0.0557 - acc: 0.9906\n",
      "Epoch 10/60\n",
      " - 0s - loss: 0.0502 - acc: 0.9930\n",
      "Epoch 11/60\n",
      " - 0s - loss: 0.0456 - acc: 0.9930\n",
      "Epoch 12/60\n",
      " - 0s - loss: 0.0416 - acc: 0.9930\n",
      "Epoch 13/60\n",
      " - 0s - loss: 0.0379 - acc: 0.9930\n",
      "Epoch 14/60\n",
      " - 0s - loss: 0.0358 - acc: 0.9930\n",
      "Epoch 15/60\n",
      " - 0s - loss: 0.0314 - acc: 0.9930\n",
      "Epoch 16/60\n",
      " - 0s - loss: 0.0292 - acc: 0.9930\n",
      "Epoch 17/60\n",
      " - 0s - loss: 0.0278 - acc: 0.9930\n",
      "Epoch 18/60\n",
      " - 0s - loss: 0.0245 - acc: 0.9930\n",
      "Epoch 19/60\n",
      " - 0s - loss: 0.0224 - acc: 0.9953\n",
      "Epoch 20/60\n",
      " - 0s - loss: 0.0206 - acc: 0.9953\n",
      "Epoch 21/60\n",
      " - 0s - loss: 0.0190 - acc: 0.9953\n",
      "Epoch 22/60\n",
      " - 0s - loss: 0.0172 - acc: 0.9953\n",
      "Epoch 23/60\n",
      " - 0s - loss: 0.0159 - acc: 0.9953\n",
      "Epoch 24/60\n",
      " - 0s - loss: 0.0142 - acc: 0.9953\n",
      "Epoch 25/60\n",
      " - 0s - loss: 0.0128 - acc: 0.9953\n",
      "Epoch 26/60\n",
      " - 0s - loss: 0.0117 - acc: 0.9953\n",
      "Epoch 27/60\n",
      " - 0s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 28/60\n",
      " - 0s - loss: 0.0098 - acc: 0.9977\n",
      "Epoch 29/60\n",
      " - 0s - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 30/60\n",
      " - 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 31/60\n",
      " - 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 32/60\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 33/60\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 34/60\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 35/60\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 36/60\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 37/60\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 38/60\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 39/60\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 40/60\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 41/60\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 42/60\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 43/60\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 44/60\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 45/60\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 46/60\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 47/60\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 48/60\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 49/60\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 50/60\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 51/60\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 52/60\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 53/60\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 54/60\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 55/60\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 56/60\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 57/60\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 58/60\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 59/60\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 60/60\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_4 = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.12153863490846027, Accuracy: 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methodology_#Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='sigmoid', input_dim=30))\n",
    "model.add(Dense(units=50, activation='sigmoid'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "426/426 [==============================] - 0s 720us/step - loss: 0.9585 - acc: 0.3732\n",
      "Epoch 2/60\n",
      "426/426 [==============================] - 0s 60us/step - loss: 0.6134 - acc: 0.6690\n",
      "Epoch 3/60\n",
      "426/426 [==============================] - 0s 98us/step - loss: 0.5403 - acc: 0.6667\n",
      "Epoch 4/60\n",
      "426/426 [==============================] - 0s 70us/step - loss: 0.4592 - acc: 0.8239\n",
      "Epoch 5/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.3924 - acc: 0.9131\n",
      "Epoch 6/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.3309 - acc: 0.9272\n",
      "Epoch 7/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.2808 - acc: 0.9272\n",
      "Epoch 8/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.2390 - acc: 0.9390\n",
      "Epoch 9/60\n",
      "426/426 [==============================] - 0s 70us/step - loss: 0.2059 - acc: 0.9390\n",
      "Epoch 10/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.1800 - acc: 0.9507\n",
      "Epoch 11/60\n",
      "426/426 [==============================] - 0s 94us/step - loss: 0.1582 - acc: 0.9624\n",
      "Epoch 12/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.1423 - acc: 0.9624\n",
      "Epoch 13/60\n",
      "426/426 [==============================] - 0s 83us/step - loss: 0.1284 - acc: 0.9695\n",
      "Epoch 14/60\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0927 - acc: 1.000 - 0s 91us/step - loss: 0.1175 - acc: 0.9789\n",
      "Epoch 15/60\n",
      "426/426 [==============================] - 0s 92us/step - loss: 0.1080 - acc: 0.9812\n",
      "Epoch 16/60\n",
      "426/426 [==============================] - 0s 82us/step - loss: 0.1002 - acc: 0.9812\n",
      "Epoch 17/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0939 - acc: 0.9812\n",
      "Epoch 18/60\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0882 - acc: 0.9812\n",
      "Epoch 19/60\n",
      "426/426 [==============================] - 0s 69us/step - loss: 0.0839 - acc: 0.9812\n",
      "Epoch 20/60\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0794 - acc: 0.9859\n",
      "Epoch 21/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0761 - acc: 0.9859\n",
      "Epoch 22/60\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.0732 - acc: 0.9859\n",
      "Epoch 23/60\n",
      "426/426 [==============================] - 0s 80us/step - loss: 0.0711 - acc: 0.9883\n",
      "Epoch 24/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0692 - acc: 0.9883\n",
      "Epoch 25/60\n",
      "426/426 [==============================] - 0s 70us/step - loss: 0.0668 - acc: 0.9906\n",
      "Epoch 26/60\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.2233 - acc: 0.968 - 0s 75us/step - loss: 0.0650 - acc: 0.9906\n",
      "Epoch 27/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0632 - acc: 0.9906\n",
      "Epoch 28/60\n",
      "426/426 [==============================] - 0s 73us/step - loss: 0.0621 - acc: 0.9906\n",
      "Epoch 29/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0603 - acc: 0.9906\n",
      "Epoch 30/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0590 - acc: 0.9906\n",
      "Epoch 31/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.0580 - acc: 0.9906\n",
      "Epoch 32/60\n",
      "426/426 [==============================] - 0s 72us/step - loss: 0.0567 - acc: 0.9906\n",
      "Epoch 33/60\n",
      "426/426 [==============================] - 0s 63us/step - loss: 0.0557 - acc: 0.9906\n",
      "Epoch 34/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.0548 - acc: 0.9906\n",
      "Epoch 35/60\n",
      "426/426 [==============================] - 0s 82us/step - loss: 0.0540 - acc: 0.9906\n",
      "Epoch 36/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0532 - acc: 0.9906\n",
      "Epoch 37/60\n",
      "426/426 [==============================] - 0s 74us/step - loss: 0.0528 - acc: 0.9906\n",
      "Epoch 38/60\n",
      "426/426 [==============================] - 0s 83us/step - loss: 0.0529 - acc: 0.9906\n",
      "Epoch 39/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0516 - acc: 0.9906\n",
      "Epoch 40/60\n",
      "426/426 [==============================] - 0s 74us/step - loss: 0.0506 - acc: 0.9906\n",
      "Epoch 41/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0500 - acc: 0.9906\n",
      "Epoch 42/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.0497 - acc: 0.9906\n",
      "Epoch 43/60\n",
      "426/426 [==============================] - 0s 88us/step - loss: 0.0490 - acc: 0.9906\n",
      "Epoch 44/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.0488 - acc: 0.9906\n",
      "Epoch 45/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.0480 - acc: 0.9906\n",
      "Epoch 46/60\n",
      "426/426 [==============================] - 0s 81us/step - loss: 0.0476 - acc: 0.9906\n",
      "Epoch 47/60\n",
      "426/426 [==============================] - 0s 91us/step - loss: 0.0473 - acc: 0.9906\n",
      "Epoch 48/60\n",
      "426/426 [==============================] - 0s 62us/step - loss: 0.0470 - acc: 0.9906\n",
      "Epoch 49/60\n",
      "426/426 [==============================] - 0s 78us/step - loss: 0.0465 - acc: 0.9906\n",
      "Epoch 50/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0463 - acc: 0.9906\n",
      "Epoch 51/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0461 - acc: 0.9906\n",
      "Epoch 52/60\n",
      "426/426 [==============================] - 0s 78us/step - loss: 0.0455 - acc: 0.9906\n",
      "Epoch 53/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.0452 - acc: 0.9906\n",
      "Epoch 54/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0451 - acc: 0.9906\n",
      "Epoch 55/60\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0452 - acc: 0.9906\n",
      "Epoch 56/60\n",
      "426/426 [==============================] - 0s 65us/step - loss: 0.0444 - acc: 0.9906\n",
      "Epoch 57/60\n",
      "426/426 [==============================] - 0s 83us/step - loss: 0.0441 - acc: 0.9906\n",
      "Epoch 58/60\n",
      "426/426 [==============================] - 0s 66us/step - loss: 0.0440 - acc: 0.9906\n",
      "Epoch 59/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.0437 - acc: 0.9906\n",
      "Epoch 60/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0435 - acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_5 = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.08020353396553416, Accuracy: 0.972027972027972, Testing: <keras.engine.sequential.Sequential object at 0x111277a58>\n"
     ]
    }
   ],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}, Testing: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methodology_#Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='linear', input_dim=30))\n",
    "model.add(Dense(units=50, activation='linear'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_6 = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.1730704890148693, Accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Methodology_#Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='tanh', input_dim=30))\n",
    "model.add(Dense(units=50, activation='tanh'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "426/426 [==============================] - 0s 919us/step - loss: 0.3735 - acc: 0.8310\n",
      "Epoch 2/60\n",
      "426/426 [==============================] - 0s 72us/step - loss: 0.1295 - acc: 0.9507\n",
      "Epoch 3/60\n",
      "426/426 [==============================] - 0s 84us/step - loss: 0.0935 - acc: 0.9742\n",
      "Epoch 4/60\n",
      "426/426 [==============================] - 0s 61us/step - loss: 0.0761 - acc: 0.9859\n",
      "Epoch 5/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0663 - acc: 0.9906\n",
      "Epoch 6/60\n",
      "426/426 [==============================] - 0s 69us/step - loss: 0.0611 - acc: 0.9906\n",
      "Epoch 7/60\n",
      "426/426 [==============================] - 0s 73us/step - loss: 0.0570 - acc: 0.9906\n",
      "Epoch 8/60\n",
      "426/426 [==============================] - 0s 67us/step - loss: 0.0545 - acc: 0.9930\n",
      "Epoch 9/60\n",
      "426/426 [==============================] - 0s 72us/step - loss: 0.0515 - acc: 0.9883\n",
      "Epoch 10/60\n",
      "426/426 [==============================] - 0s 70us/step - loss: 0.0500 - acc: 0.9883\n",
      "Epoch 11/60\n",
      "426/426 [==============================] - 0s 66us/step - loss: 0.0498 - acc: 0.9859\n",
      "Epoch 12/60\n",
      "426/426 [==============================] - 0s 84us/step - loss: 0.0459 - acc: 0.9883\n",
      "Epoch 13/60\n",
      "426/426 [==============================] - 0s 81us/step - loss: 0.0441 - acc: 0.9930\n",
      "Epoch 14/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.0425 - acc: 0.9930\n",
      "Epoch 15/60\n",
      "426/426 [==============================] - 0s 80us/step - loss: 0.0415 - acc: 0.9906\n",
      "Epoch 16/60\n",
      "426/426 [==============================] - 0s 89us/step - loss: 0.0405 - acc: 0.9906\n",
      "Epoch 17/60\n",
      "426/426 [==============================] - 0s 81us/step - loss: 0.0388 - acc: 0.9906\n",
      "Epoch 18/60\n",
      "426/426 [==============================] - 0s 86us/step - loss: 0.0380 - acc: 0.9906\n",
      "Epoch 19/60\n",
      "426/426 [==============================] - 0s 69us/step - loss: 0.0374 - acc: 0.9930\n",
      "Epoch 20/60\n",
      "426/426 [==============================] - 0s 64us/step - loss: 0.0354 - acc: 0.9906\n",
      "Epoch 21/60\n",
      "426/426 [==============================] - 0s 79us/step - loss: 0.0343 - acc: 0.9906\n",
      "Epoch 22/60\n",
      "426/426 [==============================] - 0s 65us/step - loss: 0.0330 - acc: 0.9930\n",
      "Epoch 23/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.0320 - acc: 0.9930\n",
      "Epoch 24/60\n",
      "426/426 [==============================] - 0s 83us/step - loss: 0.0333 - acc: 0.9906\n",
      "Epoch 25/60\n",
      "426/426 [==============================] - 0s 60us/step - loss: 0.0306 - acc: 0.9906\n",
      "Epoch 26/60\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0279 - acc: 0.9930\n",
      "Epoch 27/60\n",
      "426/426 [==============================] - 0s 77us/step - loss: 0.0274 - acc: 0.9906\n",
      "Epoch 28/60\n",
      "426/426 [==============================] - 0s 69us/step - loss: 0.0251 - acc: 0.9930\n",
      "Epoch 29/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.0250 - acc: 0.9930\n",
      "Epoch 30/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0240 - acc: 0.9930\n",
      "Epoch 31/60\n",
      "426/426 [==============================] - 0s 73us/step - loss: 0.0233 - acc: 0.9930\n",
      "Epoch 32/60\n",
      "426/426 [==============================] - 0s 63us/step - loss: 0.0222 - acc: 0.9930\n",
      "Epoch 33/60\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0212 - acc: 1.000 - 0s 76us/step - loss: 0.0211 - acc: 0.9930\n",
      "Epoch 34/60\n",
      "426/426 [==============================] - 0s 81us/step - loss: 0.0202 - acc: 0.9930\n",
      "Epoch 35/60\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.0185 - acc: 1.000 - 0s 77us/step - loss: 0.0199 - acc: 0.9930\n",
      "Epoch 36/60\n",
      "426/426 [==============================] - 0s 75us/step - loss: 0.0177 - acc: 0.9930\n",
      "Epoch 37/60\n",
      "426/426 [==============================] - 0s 78us/step - loss: 0.0169 - acc: 0.9953\n",
      "Epoch 38/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0161 - acc: 0.9953\n",
      "Epoch 39/60\n",
      "426/426 [==============================] - 0s 85us/step - loss: 0.0165 - acc: 0.9930\n",
      "Epoch 40/60\n",
      "426/426 [==============================] - 0s 86us/step - loss: 0.0150 - acc: 0.9930\n",
      "Epoch 41/60\n",
      "426/426 [==============================] - 0s 70us/step - loss: 0.0180 - acc: 0.9977\n",
      "Epoch 42/60\n",
      "426/426 [==============================] - 0s 76us/step - loss: 0.0142 - acc: 0.9977\n",
      "Epoch 43/60\n",
      "426/426 [==============================] - 0s 88us/step - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 44/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0118 - acc: 0.9953\n",
      "Epoch 45/60\n",
      "426/426 [==============================] - 0s 94us/step - loss: 0.0114 - acc: 0.9977\n",
      "Epoch 46/60\n",
      "426/426 [==============================] - 0s 71us/step - loss: 0.0110 - acc: 0.9977\n",
      "Epoch 47/60\n",
      "426/426 [==============================] - 0s 92us/step - loss: 0.0106 - acc: 0.9977\n",
      "Epoch 48/60\n",
      "426/426 [==============================] - 0s 65us/step - loss: 0.0100 - acc: 0.9977\n",
      "Epoch 49/60\n",
      "426/426 [==============================] - 0s 63us/step - loss: 0.0097 - acc: 0.9977\n",
      "Epoch 50/60\n",
      "426/426 [==============================] - 0s 82us/step - loss: 0.0106 - acc: 0.9977\n",
      "Epoch 51/60\n",
      "426/426 [==============================] - 0s 64us/step - loss: 0.0109 - acc: 0.9977\n",
      "Epoch 52/60\n",
      "426/426 [==============================] - 0s 91us/step - loss: 0.0096 - acc: 0.9977\n",
      "Epoch 53/60\n",
      "426/426 [==============================] - 0s 85us/step - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 54/60\n",
      "426/426 [==============================] - 0s 92us/step - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 55/60\n",
      "426/426 [==============================] - 0s 68us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "426/426 [==============================] - 0s 93us/step - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 57/60\n",
      "426/426 [==============================] - 0s 63us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "426/426 [==============================] - 0s 65us/step - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 59/60\n",
      "426/426 [==============================] - 0s 83us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "426/426 [==============================] - 0s 87us/step - loss: 0.0060 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_7 = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.12085719887333138, Accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree (C4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90209790209790208"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ref: 21-2-4\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e21fb9ffcc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path, f, prog)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m                 \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m             )\n\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                 \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# WARNING! BOILERPLATE CODE HERE! \n",
    "# Use this to visualize the tree\n",
    "import graphviz \n",
    "target_names = [\"Benign\", \"Malignant\"]\n",
    "feature_names = data.columns\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, out_file=None, \n",
    "    feature_names=feature_names,  \n",
    "    class_names=target_names,  \n",
    "    filled=True, rounded=True,  \n",
    "    special_characters=True)  \n",
    "\n",
    "import pydotplus\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png('tree.png')\n",
    "\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (NB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Library of Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9389671361502347\n",
      "Testing Data Score: 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 21\n",
      "Best features : Index(['radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean',\n",
      "       'concavity_mean', 'concave points_mean', 'symmetry_mean',\n",
      "       'fractal_dimension_mean', 'radius_se', 'perimeter_se', 'area_se',\n",
      "       'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',\n",
      "       'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
      "       'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "clf_2 = RandomForestClassifier() \n",
    "rfecv = RFECV(estimator=clf_2, step=1, cv=5,scoring='accuracy') #5-fold cross-validation\n",
    "rfecv = rfecv.fit(X_train, y_train)\n",
    "\n",
    "print('Optimal number of features :', rfecv.n_features_)\n",
    "print('Best features :', X_train.columns[rfecv.support_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEfCAYAAACwF+reAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2294e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score of number of selected features\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.savefig('Feature_Selection.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 22 Features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_features= cancer.drop(cancer.columns[[9, 10, 13, 15, 16, 17, 25, 30 ]], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer_features.drop(\"diagnosis\", axis=1)\n",
    "y = cancer[\"diagnosis\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='relu', input_dim=22))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning #Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='sigmoid', input_dim=22))\n",
    "model.add(Dense(units=50, activation='sigmoid'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_3 = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quantify our Trained Model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_hist_relu = clf_4.history['loss'] \n",
    "acc_hist_relu = clf_4.history['acc'] \n",
    "loss_hist_sigmoid = clf_5.history['loss'] \n",
    "acc_hist_sigmoid = clf_5.history['acc'] \n",
    "loss_hist_linear = clf_6.history['loss'] \n",
    "acc_hist_linear = clf_6.history['acc'] \n",
    "loss_hist_tanh = clf_6.history['loss'] \n",
    "acc_hist_tanh = clf_6.history['acc'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_axis = list(range(1, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22f28b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss & Accuracy\")\n",
    "ax1.plot(x_axis, loss_hist_relu)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_axis, acc_hist_relu)\n",
    "# ax4.plot(x_axis, acc_hist_sigmoid)\n",
    "ax3 = ax1.twinx()\n",
    "ax3.plot(x_axis, loss_hist_sigmoid)\n",
    "\n",
    "# plt.savefig('Feature_Selection.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiztion False Positive & Flase Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test,clf_3.predict(X_test))\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split data train 70 % and test 30 %\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#random forest classifier with n_estimators=10 (default)\n",
    "clf_rf = RandomForestClassifier(random_state=43)      \n",
    "clr_rf = clf_rf.fit(x_train,y_train)\n",
    "\n",
    "ac = accuracy_score(y_test,clf_rf.predict(x_test))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test,clf_rf.predict(x_test))\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
